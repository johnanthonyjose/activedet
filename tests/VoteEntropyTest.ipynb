{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyInstances:\n",
    "    def __init__(self, prob_scores):\n",
    "        self.prob_scores = torch.tensor(prob_scores)\n",
    "        self.scores = torch.tensor([])\n",
    "        self.pred_classes = torch.tensor([])\n",
    "        if len(self.prob_scores) > 0:\n",
    "            self.scores, self.pred_classes = torch.max(self.prob_scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummydata1_batches():\n",
    "    \"\"\"Inspired from modAL Vote entropy\n",
    "    https://modal-python.readthedocs.io/en/latest/content/query_strategies/Disagreement-sampling.html#vote-entropy\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {   # there are two votes for 0, one votes for 1 and zero votes for 2\n",
    "            \"img_1\": [  #class: 0    1     2        \n",
    "                DummyInstances([[0.8, 0.1, 0.0]]),  # \\\n",
    "                DummyInstances([[0.3, 0.7, 0.0]]),  # |\n",
    "                DummyInstances([[1.0, 0.0, 0.0]]),  # |  <-- class probabilities for the first classifier\n",
    "            ]                                       # | \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_2\": [\n",
    "                DummyInstances([[0.0, 1.0, 0.0]]),  # \\\n",
    "                DummyInstances([[0.4, 0.6, 0.0]]),  # |\n",
    "                DummyInstances([[0.0, 0.0, 1.0]]),  # |  <-- class probabilities for the second classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_3\": [\n",
    "                DummyInstances([[0.7, 0.2, 0.1]]),  # \\\n",
    "                DummyInstances([[0.4, 0.0, 0.6]]),  # |\n",
    "                DummyInstances([[0.3, 0.5, 0.2]]),  # |  <-- class probabilities for the third classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_4\": [\n",
    "                DummyInstances([[0.0, 0.0, 1.0]]),  # \\\n",
    "                DummyInstances([[0.2, 0.3, 0.5]]),  # |\n",
    "                DummyInstances([[0.1, 0.1, 0.8]]),  # |  <-- class probabilities for the fourth classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_5\": [\n",
    "                DummyInstances([[0.0, 1.0, 0.0]]),  # \\\n",
    "                DummyInstances([[0.2, 0.3, 0.5]]),  # |\n",
    "                DummyInstances([[0.1, 0.1, 0.8]]),  # |  <-- class probabilities for the fourth classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummydata2_batches():\n",
    "    \"\"\"Inspired from modAL Consensus entropy\n",
    "    https://modal-python.readthedocs.io/en/latest/content/query_strategies/Disagreement-sampling.html#disagreement-sampling\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"img_1\": [\n",
    "                DummyInstances([[0.8, 0.1, 0.0]]),  # \\\n",
    "                DummyInstances([[0.3, 0.7, 0.0]]),  # |\n",
    "                DummyInstances([[1.0, 0.0, 0.0]]),  # |  <-- class probabilities for the first classifier\n",
    "                DummyInstances([[0.2, 0.2, 0.6]]),  # |\n",
    "                DummyInstances([[0.2, 0.7, 0.1]]),  # |\n",
    "            ]                                       # | \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_2\": [\n",
    "                DummyInstances([[0.0, 1.0, 0.0]]),  # \\\n",
    "                DummyInstances([[0.4, 0.6, 0.0]]),  # |\n",
    "                DummyInstances([[0.2, 0.7, 0.1]]),  # |  <-- class probabilities for the second classifier\n",
    "                DummyInstances([[0.3, 0.1, 0.6]]),  # |\n",
    "                DummyInstances([[0.0, 0.0, 1.0]]),  # |\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_3\": [\n",
    "                DummyInstances([[0.7, 0.2, 0.1]]),  # \\\n",
    "                DummyInstances([[0.4, 0.0, 0.6]]),  # |\n",
    "                DummyInstances([[0.3, 0.2, 0.5]]),  # |  <-- class probabilities for the third classifier\n",
    "                DummyInstances([[0.1, 0.0, 0.9]]),  # |\n",
    "                DummyInstances([[0.0, 0.1, 0.9]]),  # |\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummydata3_batches():\n",
    "    \"\"\"Inspired from modAL Consensus entropy\n",
    "    https://modal-python.readthedocs.io/en/latest/content/query_strategies/Disagreement-sampling.html#vote-entropy\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {   # there are two votes for 0, one votes for 1 and zero votes for 2\n",
    "            \"img_1\": [  #class: 0    1     2        \n",
    "                DummyInstances([[0.8, 0.1, 0.0]]),  # \\\n",
    "                DummyInstances([[0.0, 1.0, 0.0]]),  # |\n",
    "                DummyInstances([[0.7, 0.2, 0.1]]),  # |  <-- class probabilities for the first classifier\n",
    "            ]                                       # | \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_2\": [\n",
    "                DummyInstances([[0.3, 0.7, 0.0]]),  # \\\n",
    "                DummyInstances([[0.4, 0.6, 0.0]]),  # |\n",
    "                DummyInstances([[0.4, 0.0, 0.6]]),  # |  <-- class probabilities for the second classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_3\": [\n",
    "                DummyInstances([[1.0, 0.0, 0.0]]),  # \\\n",
    "                DummyInstances([[0.2, 0.7, 0.1]]),  # |\n",
    "                DummyInstances([[0.3, 0.2, 0.5]]),  # |  <-- class probabilities for the third classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_4\": [\n",
    "                DummyInstances([[0.2, 0.2, 0.6]]),  # \\\n",
    "                DummyInstances([[0.3, 0.1, 0.6]]),  # |\n",
    "                DummyInstances([[0.1, 0.0, 0.9]]),  # |  <-- class probabilities for the fourth classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "        {\n",
    "            \"img_5\": [\n",
    "                DummyInstances([[0.2, 0.7, 0.1]]),  # \\\n",
    "                DummyInstances([[0.0, 0.0, 1.0]]),  # |\n",
    "                DummyInstances([[0.0, 0.1, 0.9]]),  # |  <-- class probabilities for the fourth classifier\n",
    "            ]                                       # |  \n",
    "        },                                          # /\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydata1 = dummydata1_batches()\n",
    "dummydata2 = dummydata2_batches()\n",
    "dummydata3 = dummydata3_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cls_entropy(p):\n",
    "    entropy = -1 * torch.sum(p * torch.log2(p),dim=-1)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_1\n",
      "\tMC_0\n",
      "\t\t1 detections\n",
      "\tMC_1\n",
      "\t\t1 detections\n",
      "\tMC_2\n",
      "\t\t1 detections\n",
      "\n",
      "\n",
      "img_2\n",
      "\tMC_0\n",
      "\t\t1 detections\n",
      "\tMC_1\n",
      "\t\t1 detections\n",
      "\tMC_2\n",
      "\t\t1 detections\n",
      "\n",
      "\n",
      "img_3\n",
      "\tMC_0\n",
      "\t\t1 detections\n",
      "\tMC_1\n",
      "\t\t1 detections\n",
      "\tMC_2\n",
      "\t\t1 detections\n",
      "\n",
      "\n",
      "img_4\n",
      "\tMC_0\n",
      "\t\t1 detections\n",
      "\tMC_1\n",
      "\t\t1 detections\n",
      "\tMC_2\n",
      "\t\t1 detections\n",
      "\n",
      "\n",
      "img_5\n",
      "\tMC_0\n",
      "\t\t1 detections\n",
      "\tMC_1\n",
      "\t\t1 detections\n",
      "\tMC_2\n",
      "\t\t1 detections\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in dummydata1:\n",
    "    for key,MC_samples in batch.items():\n",
    "        print(key)\n",
    "        for idx,instance in enumerate(MC_samples):\n",
    "            print(\"\\tMC_{}\".format(idx))\n",
    "            print(\"\\t\\t{} detections\".format(len(instance.prob_scores)))\n",
    "#             print(instance.prob_scores)\n",
    "#             print(instance.pred_classes)\n",
    "#             print(instance.scores)\n",
    "#             print(compute_cls_entropy(instance.prob_scores))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Random Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activedet.acquisition.heuristics import RandomHeuristic\n",
    "random_heuristic = RandomHeuristic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 0, 2, 4])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "random_rank = random_heuristic(dummydata1)\n",
    "print(random_rank)\n",
    "print(len(random_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classification Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from activedet.config import add_active_learning_config\n",
    "from activedet.acquisition.heuristics import ClassificationEntropy\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_active_learning_config(cfg)\n",
    "cfg.merge_from_file(\"../configs/PascalVOC-Detection/classification_entropy_faster_rcnn.yaml\")\n",
    "cfg.ACTIVE_LEARNING.POOL.MC_SIZE = 3\n",
    "cfg.ACTIVE_LEARNING.CLS_MERGE_MODE = \"mean\"\n",
    "heuristic = ClassificationEntropy(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks, scores = heuristic(dummydata1, return_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ranks) == 5 # There's a total of 5 instances in all of the batches\n",
    "assert torch.allclose(scores, torch.tensor([0.3199, 0.2243, 0.8348,0.5562,0.5562]), atol=1e-04), f\"Calculated Score: {scores}\"\n",
    "assert torch.equal(    ranks, torch.tensor([2     , 3     , 4     , 0    , 1     ])), f\"Calculated rank: {ranks}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Vote Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import CfgNode as CN\n",
    "from activedet.acquisition.heuristics import VoteEntropy\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_active_learning_config(cfg)\n",
    "cfg.merge_from_file(\"../configs/PascalVOC-Detection/VoteEntropy_faster_rcnn.yaml\")\n",
    "cfg.ACTIVE_LEARNING.POOL.MC_SIZE = 3\n",
    "vote_heuristic = VoteEntropy(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks, scores = vote_heuristic(dummydata1, return_score=True)\n",
    "assert len(ranks) == 5 # There's a total of 5 instances in all of the batches\n",
    "assert torch.allclose(scores, torch.tensor([0.9182, 0.9182, 1.5849, 0.0, 0.9182]), atol=1e-04), f\"Calculated Score: {scores}\"\n",
    "assert torch.equal(    ranks, torch.tensor([2     , 0     , 1     , 4  , 3     ])), f\"Calculated rank: {ranks}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Consensus Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import CfgNode as CN\n",
    "from activedet.acquisition.heuristics import ConsensusEntropy\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_active_learning_config(cfg)\n",
    "cfg.merge_from_file(\"../configs/PascalVOC-Detection/ConsensusEntropy_faster_rcnn.yaml\")\n",
    "cfg.ACTIVE_LEARNING.POOL.MC_SIZE = 3\n",
    "vote_heuristic = ConsensusEntropy(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks, scores = vote_heuristic(dummydata3, return_score=True)\n",
    "assert len(ranks) == 5 # There's a total of 5 instances in all of the batches\n",
    "assert torch.allclose(scores, torch.tensor([1.1711, 1.5179, 1.4855, 1.1568, 1.1589]), atol=1e-04), f\"Calculated Score: {scores}\"\n",
    "assert torch.equal(    ranks, torch.tensor([1     , 2     ,0     ,4  ,3     ])), f\"Calculated rank: {ranks}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3747ddc6188d6a72f724494bb5c6d05ee91691bcbbb67f0a3605916547a4e69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('activedet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
